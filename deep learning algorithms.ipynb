{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploring the outcome with deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1e6314dbec07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tf.keras.models import Model\n",
    "from tf.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from tf.keras.regularizers import l2\n",
    "from tf.keras.optimizers import SGD, Adam\n",
    "from tf.keras.models import model_from_json\n",
    "# load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('editing1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "df = pd.read_csv('editing1.csv')\n",
    "\n",
    "N = df.userId.max() + 1 # number of users\n",
    "M = df.movie_idx.max() + 1 # number of movies\n",
    "\n",
    "# split into train and test\n",
    "df = shuffle(df)\n",
    "cutoff = int(0.8*len(df))\n",
    "df_train = df.iloc[:cutoff]\n",
    "df_test = df.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "K = 10 # latent dimensionality\n",
    "mu = df_train.rating.mean()\n",
    "epochs = 15\n",
    "reg = 0.005 # regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \"\"\"Get the uid for the default graph.\n\u001b[1;32m---> 66\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-481399d11b5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# keras model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mu_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (N, 1, K)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mm_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (m, 1, K)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[1;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[0;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                              input_tensor=tensor)\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'input'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[1;34m(prefix)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0m_GRAPH_UID_DICTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mprefix\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0moptional\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;31m# Returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mA\u001b[0m \u001b[0munique\u001b[0m \u001b[0midentifier\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
     ]
    }
   ],
   "source": [
    "# keras model\n",
    "u = Input(shape=(1,))\n",
    "m = Input(shape=(1,))\n",
    "u_embedding = Embedding(N, K, embeddings_regularizer=l2(reg))(u) # (N, 1, K)\n",
    "m_embedding = Embedding(M, K, embeddings_regularizer=l2(reg))(m) # (m, 1, K)\n",
    "\n",
    "# subsubmodel = Model([u, m], [u_embedding, m_embedding])\n",
    "# user_ids = df_train.userId.values[0:5]\n",
    "# movie_ids = df_train.movie_idx.values[0:5]\n",
    "# print(\"user_ids.shape\", user_ids.shape)\n",
    "# p = subsubmodel.predict([user_ids, movie_ids])\n",
    "# print(\"p[0].shape:\", p[0].shape)\n",
    "# print(\"p[1].shape:\", p[1].shape)\n",
    "# exit()\n",
    "\n",
    "\n",
    "u_bias = Embedding(N, 1, embeddings_regularizer=l2(reg))(u) # (N, 1, 1)\n",
    "m_bias = Embedding(M, 1, embeddings_regularizer=l2(reg))(m) # (M, 1, 1)\n",
    "x = Dot(axes=2)([u_embedding, m_embedding]) # (N, 1, 1)\n",
    "\n",
    "# submodel = Model([u, m], x)\n",
    "# user_ids = df_train.userId.values[0:5]\n",
    "# movie_ids = df_train.movie_idx.values[0:5]\n",
    "# p = submodel.predict([user_ids, movie_ids])\n",
    "# print(\"p.shape:\", p.shape)\n",
    "# exit()\n",
    "\n",
    "\n",
    "x = Add()([x, u_bias, m_bias])\n",
    "x = Flatten()(x) # (N, 1)\n",
    "\n",
    "model = Model(inputs=[u, m], outputs=x)\n",
    "model.compile(\n",
    "  loss='mse',\n",
    "  # optimizer='adam',\n",
    "  # optimizer=Adam(lr=0.01),\n",
    "  optimizer=SGD(lr=0.08, momentum=0.9),\n",
    "  metrics=['mse'],\n",
    ")\n",
    "\n",
    "r = model.fit(\n",
    "  x=[df_train.userId.values, df_train.movie_idx.values],\n",
    "  y=df_train.rating.values - mu,\n",
    "  epochs=epochs,\n",
    "  batch_size=128,\n",
    "  validation_data=(\n",
    "    [df_test.userId.values, df_test.movie_idx.values],\n",
    "    df_test.rating.values - mu\n",
    "  )\n",
    ")\n",
    "\n",
    "\n",
    "# plot losses\n",
    "plt.plot(r.history['loss'], label=\"train loss\")\n",
    "plt.plot(r.history['val_loss'], label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot mse\n",
    "plt.plot(r.history['mean_squared_error'], label=\"train mse\")\n",
    "plt.plot(r.history['val_mean_squared_error'], label=\"test mse\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras model without deep layers to study linearity in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-adca1b1b2182>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# load weights into new model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[1;34m(json_string, custom_objects)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_weights_per_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[0moriginal_keras_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m             original_backend)\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mforward_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbackward_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    145\u001b[0m                                         list(custom_objects.items())))\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[0mlayer_output_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0minput_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_output_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'output_layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m             \u001b[0mlayer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[1;34m(layer_data)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m                 \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[1;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[1;31m# in this case by convention `config` holds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;31m# the kwargs of the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[1;31m# Arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m             \u001b[0mconfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypically\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0mof\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[0;32m     85\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                                          name=self.name)\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \"\"\"Returns the symbolic shape of a tensor or variable.\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m     \u001b[1;31m# Arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "loaded_model.compile(\n",
    "  loss='mse',\n",
    "  # optimizer='adam',\n",
    "  # optimizer=Adam(lr=0.01),\n",
    "  optimizer=SGD(lr=0.08, momentum=0.9),\n",
    "  metrics=['mse'],\n",
    ")\n",
    "\n",
    "loaded_model.evaluate([df_test.userId.values, df_test.movie_idx.values],\n",
    "    df_test.rating.values - mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying with dense layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "df = pd.read_csv('edited1.csv')\n",
    "\n",
    "N = df.userId.max() + 1 # number of users\n",
    "M = df.movie_idx.max() + 1 # number of movies\n",
    "\n",
    "# split into train and test\n",
    "df = shuffle(df)\n",
    "cutoff = int(0.8*len(df))\n",
    "df_train = df.iloc[:cutoff]\n",
    "df_test = df.iloc[cutoff:]\n",
    "\n",
    "# initialize variables\n",
    "K = 10 # latent dimensionality\n",
    "mu = df_train.rating.mean()\n",
    "epochs = 15\n",
    "# reg = 0.0001 # regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model\n",
    "u = Input(shape=(1,))\n",
    "m = Input(shape=(1,))\n",
    "u_embedding = Embedding(N, K)(u) # (N, 1, K)\n",
    "m_embedding = Embedding(M, K)(m) # (N, 1, K)\n",
    "u_embedding = Flatten()(u_embedding) # (N, K)\n",
    "m_embedding = Flatten()(m_embedding) # (N, K)\n",
    "x = Concatenate()([u_embedding, m_embedding]) # (N, 2K)\n",
    "\n",
    "# the neural network\n",
    "x = Dense(400)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(100)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "x = Dense(1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[u, m], outputs=x)\n",
    "model.compile(\n",
    "  loss='mse',\n",
    "  # optimizer='adam',\n",
    "  # optimizer=Adam(lr=0.01),\n",
    "  optimizer=SGD(lr=0.08, momentum=0.9),\n",
    "  metrics=['mse'],\n",
    ")\n",
    "\n",
    "r = model.fit(\n",
    "  x=[df_train.userId.values, df_train.movie_idx.values],\n",
    "  y=df_train.rating.values - mu,\n",
    "  epochs=epochs,\n",
    "  batch_size=128,\n",
    "  validation_data=(\n",
    "    [df_test.userId.values, df_test.movie_idx.values],\n",
    "    df_test.rating.values - mu\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(r.history['loss'], label=\"train loss\")\n",
    "plt.plot(r.history['val_loss'], label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot mse\n",
    "plt.plot(r.history['mean_squared_error'], label=\"train mse\")\n",
    "plt.plot(r.history['val_mean_squared_error'], label=\"test mse\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## residual networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dot, Add, Flatten, Dense, Concatenate\n",
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "df = pd.read_csv('editing1.csv')\n",
    "\n",
    "N = df.userId.max() + 1 # number of users\n",
    "M = df.movie_idx.max() + 1 # number of movies\n",
    "\n",
    "# split into train and test\n",
    "df = shuffle(df)\n",
    "cutoff = int(0.8*len(df))\n",
    "df_train = df.iloc[:cutoff]\n",
    "df_test = df.iloc[cutoff:]\n",
    "\n",
    "# initialize variables\n",
    "K = 10 # latent dimensionality\n",
    "mu = df_train.rating.mean()\n",
    "epochs = 15\n",
    "reg = 0. # regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model\n",
    "u = Input(shape=(1,))\n",
    "m = Input(shape=(1,))\n",
    "u_embedding = Embedding(N, K)(u) # (N, 1, K)\n",
    "m_embedding = Embedding(M, K)(m) # (N, 1, K)\n",
    "\n",
    "\n",
    "##### main branch\n",
    "u_bias = Embedding(N, 1)(u) # (N, 1, 1)\n",
    "m_bias = Embedding(M, 1)(m) # (N, 1, 1)\n",
    "x = Dot(axes=2)([u_embedding, m_embedding]) # (N, 1, 1)\n",
    "x = Add()([x, u_bias, m_bias])\n",
    "x = Flatten()(x) # (N, 1)\n",
    "\n",
    "\n",
    "##### side branch\n",
    "u_embedding = Flatten()(u_embedding) # (N, K)\n",
    "m_embedding = Flatten()(m_embedding) # (N, K)\n",
    "y = Concatenate()([u_embedding, m_embedding]) # (N, 2K)\n",
    "y = Dense(400)(y)\n",
    "y = Activation('elu')(y)\n",
    "# y = Dropout(0.5)(y)\n",
    "y = Dense(1)(y)\n",
    "\n",
    "\n",
    "##### merge\n",
    "x = Add()([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[u, m], outputs=x)\n",
    "model.compile(\n",
    "  loss='mse',\n",
    "  # optimizer='adam',\n",
    "  # optimizer=Adam(lr=0.01),\n",
    "  optimizer=SGD(lr=0.08, momentum=0.9),\n",
    "  metrics=['mse'],\n",
    ")\n",
    "\n",
    "r = model.fit(\n",
    "  x=[df_train.userId.values, df_train.movie_idx.values],\n",
    "  y=df_train.rating.values - mu,\n",
    "  epochs=epochs,\n",
    "  batch_size=128,\n",
    "  validation_data=(\n",
    "    [df_test.userId.values, df_test.movie_idx.values],\n",
    "    df_test.rating.values - mu\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(r.history['loss'], label=\"train loss\")\n",
    "plt.plot(r.history['val_loss'], label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot mse\n",
    "plt.plot(r.history['mean_squared_error'], label=\"train mse\")\n",
    "plt.plot(r.history['val_mean_squared_error'], label=\"test mse\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
